{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad49416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a85b5f",
   "metadata": {},
   "source": [
    "Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(r\"IRAss2\\NER_datasets\\hindi_ner\\hi_train.conll\",\"r\", encoding = \"UTF-8\", errors = 'ignore')\n",
    "f = 0\n",
    "flag = False\n",
    "data = {\"sentence\": [], \"word_labels\": []}\n",
    "tokens = []\n",
    "ner_tags = []\n",
    "tags = [\"O\"]\n",
    "while True:\n",
    "    line = file1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    f += 1\n",
    "    if line[0:5] == \"# id \":\n",
    "        # data[\"id\"].append(line[5:41])\n",
    "        if tokens:\n",
    "            data[\"sentence\"].append(tokens)\n",
    "            data[\"word_labels\"].append(ner_tags)\n",
    "            tokens = []\n",
    "            ner_tags = []\n",
    "    else:\n",
    "        if line:\n",
    "            try:\n",
    "                words = line.split()\n",
    "                tokens.append(words[0])\n",
    "                ner_tags.append(words[3])\n",
    "                tags.append(words[3])\n",
    "            except:\n",
    "                pass\n",
    "if tokens:\n",
    "    data[\"sentence\"].append(tokens)\n",
    "    data[\"word_labels\"].append(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb030b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame.from_dict(data)\n",
    "train_dataset\n",
    "tags = list(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972685da",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(tags)}\n",
    "ids_to_labels = {v: k for v, k in enumerate(tags)}\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5012d00",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(r\"IRAss2\\NER_datasets\\hindi_ner\\hi_dev.conll\",\"r\", encoding = \"UTF-8\", errors = 'ignore')\n",
    "f = 0\n",
    "flag = False\n",
    "data = {\"sentence\": [], \"word_labels\": []}\n",
    "tokens = []\n",
    "ner_tags = []\n",
    "tags = [\"O\"]\n",
    "while True:\n",
    "    line = file1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    f += 1\n",
    "    if line[0:5] == \"# id \":\n",
    "        # data[\"id\"].append(line[5:41])\n",
    "        if tokens:\n",
    "            data[\"sentence\"].append(tokens)\n",
    "            data[\"word_labels\"].append(ner_tags)\n",
    "            tokens = []\n",
    "            ner_tags = []\n",
    "    else:\n",
    "        if line:\n",
    "            try:\n",
    "                words = line.split()\n",
    "                tokens.append(words[0])\n",
    "                ner_tags.append(words[3])\n",
    "                tags.append(words[3])\n",
    "            except:\n",
    "                pass\n",
    "if tokens:\n",
    "    data[\"sentence\"].append(tokens)\n",
    "    data[\"word_labels\"].append(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dfaa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.DataFrame.from_dict(data)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.word_labels[index]\n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             is_split_into_words=True,\n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        # print(sentence)\n",
    "        # print(word_labels)\n",
    "        encoded_labels = np.ones(MAX_LEN, dtype=int) * -100\n",
    "        i = -1\n",
    "        for idx, j in enumerate(tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])):\n",
    "          # print(j)\n",
    "          if j == \"<pad>\":\n",
    "            break\n",
    "          if j[0] == \"[\":\n",
    "            continue\n",
    "          if j[0] == \"‚ñÅ\":\n",
    "            i += 1\n",
    "          try:\n",
    "            encoded_labels[idx] = labels_to_ids[word_labels[i]]\n",
    "          except:\n",
    "            pass\n",
    "\n",
    "          \n",
    "        # print(encoded_labels)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels]\n",
    "        item = {key: np.array(val) for key, val in encoding.items()}\n",
    "        item['labels'] = np.array(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580cb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "    print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ab0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d169c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BertForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44585c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss = model(input_ids=ids, attention_mask=mask, labels=labels)[0]\n",
    "        tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels)[1]\n",
    "#         print(model(input_ids=ids, attention_mask=mask, labels=labels)[0])\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            \n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf967c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "labels = [[i] for i in labels]\n",
    "predictions = [[i] for i in predictions]\n",
    "# predictions = list(np.expand_dims(predictions, axis = 1))\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e476d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273b1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
